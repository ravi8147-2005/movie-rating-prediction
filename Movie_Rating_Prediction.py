# -*- coding: utf-8 -*-
"""Movie rating model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lhb4WTvkgZha3RpxD7T62KVECbyp84_n
"""

import pandas as pd
from ast import literal_eval

# Load the data
movies_df = pd.read_csv('tmdb_5000_movies.csv')
credits_df = pd.read_csv('tmdb_5000_credits.csv')

# Merge datasets on id
credits_df.rename(columns={'movie_id': 'id'}, inplace=True)
merged_df = movies_df.merge(credits_df, on='id')

# Extract genres
merged_df['genres'] = merged_df['genres'].apply(lambda x: [i['name'] for i in literal_eval(x)])

# Extract top 3 actors
def get_top_cast(cast_str):
    cast_list = literal_eval(cast_str)
    return [actor['name'] for actor in cast_list[:3]]
merged_df['top_cast'] = merged_df['cast'].apply(get_top_cast)

# Extract director
def get_director(crew_str):
    crew_list = literal_eval(crew_str)
    for crew in crew_list:
        if crew['job'] == 'Director':
            return crew['name']
    return None
merged_df['director'] = merged_df['crew'].apply(get_director)

merged_df.to_csv('cleaned_movies.csv', index=False)

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer

# Load the fixed and cleaned dataset
df = pd.read_csv("cleaned_movies_fixed_clean.csv")

# Keep only relevant columns
df = df[['genres', 'top_cast', 'director', 'budget', 'runtime', 'popularity', 'vote_average']]

# Fill missing values
df.fillna('', inplace=True)

# Combine text features
df['combined_text'] = df['genres'] + ' ' + df['top_cast'] + ' ' + df['director']

# Convert text features to numerical using CountVectorizer
vectorizer = CountVectorizer(max_features=1000)
text_features = vectorizer.fit_transform(df['combined_text']).toarray()

# Combine text features with numerical features
numeric_features = df[['budget', 'runtime', 'popularity']].values

# Final feature set
X = np.hstack((text_features, numeric_features))

# Target variable
y = df['vote_average'].values

# Check shape
print("âœ… Feature matrix shape:", X.shape)
print("âœ… Target shape:", y.shape)

with open("cleaned_movies_fixed_clean.csv", 'r', encoding='utf-8', errors='ignore') as f:
    lines = f.readlines()

clean_lines = [line for line in lines if line.count('"') % 2 == 0]

with open("cleaned_movies.csv", 'w', encoding='utf-8') as f:
    f.writelines(clean_lines)

# Load the fixed file
df = pd.read_csv("cleaned_movies.csv")

for col in ['budget', 'runtime', 'popularity']:
    non_numeric = df[~df[col].apply(lambda x: str(x).replace('.', '', 1).isdigit())]
    if not non_numeric.empty:
        print(f"âš ï¸ Non-numeric values found in '{col}':")
        print(non_numeric[[col]])

# Convert to numeric and fill errors
for col in ['budget', 'runtime', 'popularity']:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Fill any missing (NaN) values with 0
df[['budget', 'runtime', 'popularity']] = df[['budget', 'runtime', 'popularity']].fillna(0)

print("Unique values in vote_average:")
print(df['vote_average'].unique()[:20])

# Convert vote_average to numeric
df['vote_average'] = pd.to_numeric(df['vote_average'], errors='coerce')

# Drop rows where vote_average is missing
df = df.dropna(subset=['vote_average'])

y = df['vote_average'].values

# Fill missing values for text columns
df[['genres', 'director', 'top_cast']] = df[['genres', 'director', 'top_cast']].fillna('')

df['combined_text'] = df['genres'] + ' ' + df['director'] + ' ' + df['top_cast']

text_features = vectorizer.transform(df['combined_text']).toarray()

# rebuild features
text_features = vectorizer.transform(df['combined_text']).toarray()
numeric_features = df[['budget', 'runtime', 'popularity']].values
X = np.hstack((text_features, numeric_features))

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("âœ… RÂ² Score:", r2_score(y_test, y_pred))
print("âœ… Mean Squared Error:", mean_squared_error(y_test, y_pred))

from sklearn.ensemble import RandomForestRegressor

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

y_rf_pred = rf_model.predict(X_test)

print("ðŸŒ² RÂ² Score (Random Forest):", r2_score(y_test, y_rf_pred))
print("ðŸŒ² Mean Squared Error:", mean_squared_error(y_test, y_rf_pred))

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_rf_pred, alpha=0.5)
plt.xlabel("Actual Ratings")
plt.ylabel("Predicted Ratings")
plt.title("ðŸŽ¬ Movie Rating Prediction")
plt.grid(True)
plt.show()

from sklearn.metrics import r2_score, mean_squared_error

print("RÂ² Score:", r2_score(y_test, y_rf_pred))
print("MSE:", mean_squared_error(y_test, y_rf_pred))

# Filter out rows with 0 ratings in y_test or predictions
valid_indices = y_test > 0
y_test = y_test[valid_indices]
y_rf_pred = y_rf_pred[valid_indices]
